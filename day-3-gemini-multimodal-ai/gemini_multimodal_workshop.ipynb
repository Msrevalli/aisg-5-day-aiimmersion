{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AISG7: Day3 - MultiModal AI with Gemini\n",
    "\n",
    "This guide will walk you through using Google AI Studio with Gemini. You'll learn how to set up and interact with this powerful AI model, understand its capabilities and learn best practices for using it effectively.\n",
    "\n",
    "## Goals\n",
    "\n",
    "By the end of this guide, you should:\n",
    "\n",
    "- Have working access to Gemini in Google AI Studio\n",
    "- Understand Gemini's capabilities\n",
    "- Be able to make basic API calls\n",
    "- Test out one multimodal aspect of Gemini\n",
    "\n",
    "** Please remember to replace your AI Studio API key in the .env file! **\n",
    "\n",
    "Notes: You might need a google cloud account; there is $300 free credits for each new user and a generous free tier.   \n",
    "For our API calls below, we are using the new Gemini 2.0-Flash experimental model which is not billed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize the generativeAI client using AI Studio key\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "\n",
    "print(\"Your message to Gemini:\")\n",
    "msg = input()\n",
    "print(\"Sending message to Gemini...\")\n",
    "\n",
    "# Generate text using the Gemini model\n",
    "\n",
    "response = model1.generate_content(msg)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini to tell a joke\n",
    "\n",
    "response = model1.generate_content(\n",
    "\"\"\"\n",
    "Tell me a joke, but do not explain why it is funny. \n",
    "Please place a carriage return after each sentence and ensure readibility.\n",
    "Use this as a starting point:\n",
    "OpenAI, Gemini and Claude are in a plane ...\"\"\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Multimodal Capabilities with Gemini\n",
    "Gemini is not just a text-based model; it can also process and generate images. Here's how you can explore its multimodal capabilities:\n",
    "\n",
    "**Image Classification / Captioning**\n",
    "\n",
    "You can provide an image to Gemini and ask it to generate a caption describing the image. This showcases Gemini's ability to understand visual content.\n",
    "\n",
    "**Image Generation**\n",
    "\n",
    "You can ask Gemini to generate images based on a text description. This demonstrates its ability to translate textual concepts into visual representations.  \n",
    "Please note that the Imagen3 API for image generation is still in beta and not publically available.\n",
    "\n",
    "**Code execution**\n",
    "\n",
    "You can ask Gemini to generate and execute code.\n",
    "\n",
    "there are more capabilities, including audio understanding and video understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# image captioning\n",
    "model = genai.GenerativeModel(model_name = \"gemini-2.0-flash-exp\")\n",
    "image_path = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Felis_catus-cat_on_snow.jpg/1024px-Felis_catus-cat_on_snow.jpg\"\n",
    "\n",
    "image = httpx.get(image_path)\n",
    "\n",
    "prompt = \"Caption this image.\"\n",
    "response = model.generate_content([{'mime_type':'image/jpeg', 'data': base64.b64encode(image.content).decode('utf-8')}, prompt])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code generation and execution\n",
    "\n",
    "response = model.generate_content(\n",
    "    ('What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'),\n",
    "    tools='code_execution')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And thats it folks üëè\n",
    "\n",
    "You have successfully :\n",
    "- used an API key from AI Studio and sent Gemini a handful of prompts\n",
    "- utilised multimodal capabilities of Gemini 2.0\n",
    "\n",
    "To find out more go to the docs for Gemini Python SDK\n",
    "[https://ai.google.dev/]\n",
    "\n",
    "Now the world is your oyster - get building and show us what you come up with!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day3-genai",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
